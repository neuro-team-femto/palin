% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kernel.R
\name{computing_kernel}
\alias{computing_kernel}
\title{Computing the kernel from 2AFC data}
\usage{
computing_kernel(
  data,
  participant_id = "participant",
  block_id = "block",
  trial_id = "trial",
  feature_id = "feature",
  value_id = "value",
  response_id = "response",
  method = c("difference", "glm", "glmm"),
  double_pass = TRUE
)
}
\arguments{
\item{data}{Dataframe, with reverse correlation data (in long format).}

\item{participant_id}{Numeric/Character/Factor, column in data specifying the participant ID.}

\item{block_id}{Numeric, column in data specifying the block ID.}

\item{trial_id}{Numeric, column in data specifying the trial ID.}

\item{feature_id}{Numeric/Factor, column in data specifying the feature.}

\item{value_id}{Numeric, column in data specifying the feature value.}

\item{response_id}{Numeric, column in data specifying the response.}

\item{method}{Character, the kernel computation method, either "difference", "glm", or "glmm".}

\item{double_pass}{Logical, indicating whether the last block was repeated.}
}
\value{
The original data augmented with the kernel.
}
\description{
Computing the kernel from 2AFC data. It should be noted that when using the
"glm" method, the group-level (average) kernel is simply averaged from the
individual-level kernels. To obtain \strong{shrunk} (i.e., adjusted) group-level
kernels, one needs to specify the "glmm" method.
}
\examples{
\dontrun{
# importing the self-voice data
data(self_voice)
head(self_voice)

# computing the kernel per participant
computing_kernel(data = self_voice, method = "difference")

# plotting it
computing_kernel(data = self_voice, method = "difference") |> plot()
computing_kernel(data = self_voice, method = "glm") |> plot()
}

}
\author{
Ladislas Nalborczyk \email{ladislas.nalborczyk@gmail.com}.
}
